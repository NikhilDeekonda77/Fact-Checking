{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5173ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding \n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80179073",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a912891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c9724",
   "metadata": {},
   "source": [
    "# Our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf4804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('ai_train_20_04_24')\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai_train_20_04_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b867c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splited_docs(doc, max_words_per_chunk=300):\n",
    "    words = doc.split(\" \")\n",
    "    chunks = [words[i:i + max_words_per_chunk] for i in range(0, len(words), max_words_per_chunk)]\n",
    "    result = [' '.join(chunk).strip(\"\\n\") for chunk in chunks]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be0c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentence_endings = r\"\"\"(?<=[.!?])\\s\"\"\"\n",
    "    sentences = re.split(sentence_endings, text)\n",
    "    sentences = [s.strip() for s in sentences if s]  \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7d276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return \" \".join(text.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b532bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifiing_output_for_display(a):\n",
    "    total_string = ''\n",
    "    for key,value in a.items():\n",
    "        total_string += key\n",
    "\n",
    "        all_ref = []\n",
    "        for i in value:\n",
    "            if i[\"score\"] == 0 or len(i[\"sent\"]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                sents = \",\".join(map(str, i[\"sent\"]))\n",
    "                ref = '(doc: {}, chunk_inx: {})'.format(i[\"doc\"], sents)\n",
    "                all_ref.append(ref)\n",
    "        if len(all_ref) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            total_string += \" ref: \" + str(all_ref) + \".\"\n",
    "    return total_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b33c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_prediction(statement,all_docs):\n",
    "    answers = split_into_sentences(statement)\n",
    " \n",
    "    all_results = {}\n",
    "    overall_scores_each_answer = []\n",
    "    for answer in answers:\n",
    "        scores = []\n",
    "        for i,full_doc in enumerate(all_docs):\n",
    "            splitted_docs = get_splited_docs(full_doc)\n",
    "#             _, semantic_sentences_idx = get_semantic_sentences(answer,full_doc)\n",
    "            all_scores = [infer(answer,doc) for doc in splitted_docs]\n",
    "            semantic_sentences_idx = [i for i, j in enumerate(all_scores) if j == 1]\n",
    "            if (1 in all_scores):\n",
    "                final_score = 1\n",
    "            else:\n",
    "                final_score = 0\n",
    "            scores.append({'score': final_score, 'doc': i, \"sent\": semantic_sentences_idx}) \n",
    "        \n",
    "        all_results[answer] = scores\n",
    "        overall_scores_each_answer.append(max([i['score'] for i in scores]))\n",
    "    \n",
    "    overall_score = np.mean(np.array(overall_scores_each_answer))\n",
    "    \n",
    "    all_results = modifiing_output_for_display(all_results)\n",
    "    \n",
    "    return {\"overall_score\": np.round(overall_score,2), \"info\": all_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6509f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(statement,doc):\n",
    "    pairs = [[doc, statement]]\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus(pairs, return_tensors='pt', padding=True)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.cpu().detach().numpy()\n",
    "        # convert logits to probabilities\n",
    "        scores = 1 / (1 + np.exp(-logits)).flatten()\n",
    "    if scores[0] > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8b388",
   "metadata": {},
   "source": [
    "# Testing_datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a863e",
   "metadata": {},
   "source": [
    "# dataset 1 ----  XNLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355b08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnli_dataset = load_dataset(\"xnli\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ca0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_1 = xnli_dataset[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbd182e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>I havent spoken to him again.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>I was so upset that I just started talking to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>We had a great talk.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And I thought that was a privilege, and it's s...</td>\n",
       "      <td>I was not aware that I was not the only person...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I thought that was a privilege, and it's s...</td>\n",
       "      <td>I was under the impression that I was the only...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>Davidson should not adopt the pronunciation of...</td>\n",
       "      <td>Davidson shouldn't talk in a way where bone an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>Davidson should not adopt the pronunciation of...</td>\n",
       "      <td>It would be better if Davidson rhymed the word...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel at $25 is a fair price.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel for $25 is 4,000 words pe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel for $25 is 8,000 words pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Well, I wasn't even thinking about that, but I...   \n",
       "1     Well, I wasn't even thinking about that, but I...   \n",
       "2     Well, I wasn't even thinking about that, but I...   \n",
       "3     And I thought that was a privilege, and it's s...   \n",
       "4     And I thought that was a privilege, and it's s...   \n",
       "...                                                 ...   \n",
       "5005  Davidson should not adopt the pronunciation of...   \n",
       "5006  Davidson should not adopt the pronunciation of...   \n",
       "5007  The average novel of 200,000 words for $25 wor...   \n",
       "5008  The average novel of 200,000 words for $25 wor...   \n",
       "5009  The average novel of 200,000 words for $25 wor...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0                         I havent spoken to him again.      2  \n",
       "1     I was so upset that I just started talking to ...      0  \n",
       "2                                  We had a great talk.      1  \n",
       "3     I was not aware that I was not the only person...      1  \n",
       "4     I was under the impression that I was the only...      0  \n",
       "...                                                 ...    ...  \n",
       "5005  Davidson shouldn't talk in a way where bone an...      0  \n",
       "5006  It would be better if Davidson rhymed the word...      2  \n",
       "5007       A 200,000 word novel at $25 is a fair price.      1  \n",
       "5008  A 200,000 word novel for $25 is 4,000 words pe...      2  \n",
       "5009  A 200,000 word novel for $25 is 8,000 words pe...      0  \n",
       "\n",
       "[5010 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "541bdb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_test_data = load_dataset(\"facebook/anli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b8b61",
   "metadata": {},
   "source": [
    "# dataset-2 ---- facebook/anli-test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037ed15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_2 = facebook_test_data[\"test_r1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5878ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_2 = test_dataset_2.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cdba0",
   "metadata": {},
   "source": [
    "# dataset-3 ---- facebook/anli-test-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a2b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_3 = facebook_test_data[\"test_r2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edcc8cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_3 = test_dataset_3.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b4413",
   "metadata": {},
   "source": [
    "# dataset-4 ---- facebook/anli-test-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d565b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_4 = facebook_test_data[\"test_r3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc94c608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_4 = test_dataset_4.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f3228e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_datasets = [test_dataset_1, test_dataset_2 ,test_dataset_3, test_dataset_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d35393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be67b6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:24<00:00, 126.15s/it]\n"
     ]
    }
   ],
   "source": [
    "total_results = []\n",
    "i=0\n",
    "for data in tqdm(all_test_datasets):\n",
    "    i = i+1\n",
    "    req_dataset = data[data[\"label\"] != 1 ]\n",
    "    gt = [0 if i == 0 else 1 for i in req_dataset[\"label\"].to_list()]\n",
    "    all_comp = []\n",
    "    for row in req_dataset.iterrows():\n",
    "        label = infer(row[1][\"premise\"],row[1][\"hypothesis\"])\n",
    "        all_comp.append(label)\n",
    "    \n",
    "    accuracy = accuracy_score(gt, all_comp)\n",
    "    precision = precision_score(gt, all_comp)\n",
    "    recall = recall_score(gt, all_comp)\n",
    "    f1=f1_score(gt, all_comp)\n",
    "    all_results = {}\n",
    "    all_results[\"dataset_name\"] = f\"Test_Datset_{i}\"\n",
    "    all_results[\"accuracy\"] = accuracy\n",
    "    all_results[\"precision\"] = precision\n",
    "    all_results[\"recall\"] = recall\n",
    "    all_results[\"f1\"] = f1\n",
    "    total_results.append(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beacd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(total_results).to_csv(\"results_our_deberta.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
