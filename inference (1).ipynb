{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc733fb-8254-40f6-ab6e-268acbe96c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from transformers import DataCollatorWithPadding \n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from peft import PeftModel\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab819b02-b8a1-4156-857b-00cb4a7d9572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('ai_train_04_03_2024')\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai_train_04_03_2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edefc1ef-3f25-4ca1-acc8-2471f2ad891a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_splited_docs(text, max_chunk_words=50):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    current_chunk_word_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words_in_sentence = len(sentence.split())\n",
    "        if current_chunk_word_count + words_in_sentence > max_chunk_words:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = sentence\n",
    "            current_chunk_word_count = words_in_sentence\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                current_chunk += ' '\n",
    "            current_chunk += sentence\n",
    "            current_chunk_word_count += words_in_sentence\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b9e593-d699-4aa7-82ed-cec7354988c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentence_endings = r\"\"\"(?<=[.!?])\\s\"\"\"\n",
    "    sentences = re.split(sentence_endings, text)\n",
    "    sentences = [s.strip() for s in sentences if s]  \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ca4117-efb1-4fcb-aee9-5035cd2c13bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return \" \".join(text.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b31099-f5db-470f-9009-08be599edd3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modifiing_output_for_display(a):\n",
    "    total_string = ''\n",
    "    for key,value in a.items():\n",
    "        total_string += key\n",
    "\n",
    "        all_ref = []\n",
    "        for i in value:\n",
    "            if i[\"score\"] == 0 or len(i[\"sent\"]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                sents = \",\".join(map(str, i[\"sent\"]))\n",
    "                ref = '(doc: {}, chunk_inx: {})'.format(i[\"doc\"], sents)\n",
    "                all_ref.append(ref)\n",
    "        if len(all_ref) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            total_string += \" ref: \" + str(all_ref) + \".\"\n",
    "    return total_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b77a554-249f-421d-ac25-c9fb64d842f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_overall_prediction(statement,all_docs):\n",
    "    answers = split_into_sentences(statement)\n",
    " \n",
    "    all_results = {}\n",
    "    overall_scores_each_answer = []\n",
    "    for answer in answers:\n",
    "        scores = []\n",
    "        for i,full_doc in enumerate(all_docs):\n",
    "            splitted_docs = get_splited_docs(full_doc)\n",
    "#             _, semantic_sentences_idx = get_semantic_sentences(answer,full_doc)\n",
    "            all_scores = [infer(answer,doc) for doc in splitted_docs]\n",
    "            semantic_sentences_idx = [i for i, j in enumerate(all_scores) if j == 1]\n",
    "            if (1 in all_scores):\n",
    "                final_score = 1\n",
    "            else:\n",
    "                final_score = 0\n",
    "            scores.append({'score': final_score, 'doc': i, \"sent\": semantic_sentences_idx}) \n",
    "        \n",
    "        all_results[answer] = scores\n",
    "        overall_scores_each_answer.append(max([i['score'] for i in scores]))\n",
    "    \n",
    "    overall_score = np.mean(np.array(overall_scores_each_answer))\n",
    "    \n",
    "    all_results = modifiing_output_for_display(all_results)\n",
    "    \n",
    "    return {\"overall_score\": np.round(overall_score,2), \"info\": all_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d96a4f6f-7b99-4e90-bdc5-130c7bb25109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(statement,doc):\n",
    "    pairs = [[doc, statement]]\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus(pairs, return_tensors='pt', padding=True)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.cpu().detach().numpy()\n",
    "        # convert logits to probabilities\n",
    "        scores = 1 / (1 + np.exp(-logits)).flatten()\n",
    "#     return scores\n",
    "    if scores[0] > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56aab6b7-f42b-4891-b1cb-5d7d139765eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc1 = \"\"\" Nikhil is a passionate AI enthusiast currently pursuing his master's degree in Artificial Intelligence. With a unique blend of experience as a former SDE at LTIMindtree, where he collaborated with an international bank to develop a mobile application, he brings in-depth expertise in software development. His tenure at LTIMindtree honed his skills in writing efficient code, utilizing tools like Git, JIRA, Postman API, MySQL, and PostgreSQL, and fostering cross-team collaboration, communication, and teamwork.\"\"\"\n",
    "\n",
    "desc2 = \"\"\"During his undergraduate years, he delved into the realm of machine learning as an intern at NHAI, where he focused on predicting factors leading to road rutting. His exposure to Google Cloud Platform (GCP) and its suite of tools such as BigQueryML, LookML, AutoML, and VertexAPI further augmented his skill set. He can proficiently handle tasks ranging from creating virtual machines and VPNs to executing complex data analyses using BigQueryML and developing insightful visualizations with Tableau.\"\"\"\n",
    "\n",
    "desc3 = \"\"\"With a keen interest in harnessing the power of data, he is adept at statistical analysis, numerical optimization, and implementing machine learning and deep learning algorithms. His expertise spans Python, C, R, PyTorch, TensorFlow, Keras, Selenium, Hadoop, Spark, PostgreSQL, MySQL, and web scraping, enabling him to tackle diverse challenges in data engineering, machine learning, and data analysis. As he embark on the next phase of his career journey, he is eagerly seeking internship opportunities that align with his passion for data-driven insights and innovation.\"\"\"\n",
    "\n",
    "desc4 = \"\"\"He had the opportunity to work on diverse projects that showcase his skills and interests in AI and data science. For instance, one of his projects involved enhancing LLM Reliability through an Automated Fact-Checking System using a Cross-Encoder Model. He trained the model with a vast dataset of one million instances, deployed it on Google Cloud Platform for efficient real-time fact verification, and implemented a validation mechanism to ensure transparency and trustworthiness in information dissemination.\"\"\"\n",
    "\n",
    "desc = [desc1, desc2, desc3, desc4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a6965b-72ad-4ba8-a762-9dbb50c8dc76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement:  Nikhil is pursuing masters.\n",
      "fact_result:  {'overall_score': 1.0, 'info': \"Nikhil is pursuing masters. ref: ['(doc: 0, chunk_inx: 0)'].\"} \n",
      "\n",
      "\n",
      "statement:  Nikhil knows python.\n",
      "fact_result:  {'overall_score': 1.0, 'info': \"Nikhil knows python. ref: ['(doc: 2, chunk_inx: 1)'].\"} \n",
      "\n",
      "\n",
      "statement:  Nikhil is pursuing masters in Cybersecurity.\n",
      "fact_result:  {'overall_score': 0.0, 'info': 'Nikhil is pursuing masters in Cybersecurity.'} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st1 = \"Nikhil is pursuing masters.\"\n",
    "st2 = \"Nikhil knows python.\"\n",
    "st3 = \"Nikhil is pursuing masters in Cybersecurity.\"\n",
    "\n",
    "sts = [st1, st2, st3]\n",
    "for st in sts:\n",
    "    print('statement: ',st)\n",
    "    result = get_overall_prediction(st, desc)\n",
    "    print('fact_result: ',result, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f555d0b-032b-4809-ac65-f0b0c443779b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(st1, desc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594d6618-42fa-4d91-8c94-5dfb07b8deef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(st3, desc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b5eda-a8ad-47d1-a44a-c63bf8768a99",
   "metadata": {},
   "source": [
    "## Demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7b1f56-36a1-4c00-8dd8-8a3cf6ce75be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement:  Nikhil completed his masters\n",
      "fact_result:  {'overall_score': 0.0, 'info': 'Nikhil completed his masters'}\n"
     ]
    }
   ],
   "source": [
    "st4 = \"Nikhil completed his masters\"\n",
    "print('statement: ',st4)\n",
    "result = get_overall_prediction(st4, desc)\n",
    "print('fact_result: ',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ddf8db4-cc70-46cd-b69a-7a4fd2c2ede3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement:  Nikhil worked on various projects\n",
      "fact_result:  {'overall_score': 1.0, 'info': \"Nikhil worked on various projects ref: ['(doc: 0, chunk_inx: 0,1)', '(doc: 2, chunk_inx: 1)', '(doc: 3, chunk_inx: 0)'].\"}\n"
     ]
    }
   ],
   "source": [
    "st5 = \"Nikhil worked on various projects\"\n",
    "print('statement: ',st5)\n",
    "result = get_overall_prediction(st5, desc)\n",
    "print('fact_result: ',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9ee79-9a33-4650-a97f-b4ec8a827b72",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ed13d50-4f3e-414e-9a0b-d26175cf68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "paws_dataset = load_dataset(\"paws\", \"labeled_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757f9a87-5ad6-437e-a481-4fcc851ea1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paws_test = paws_dataset[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4c2f1b-bf81-456f-84d6-1e9c49c90cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "paws_test_examples = []\n",
    "for i, row in paws_test.iterrows():\n",
    "    paws_test_examples.append(InputExample(texts=[row['sentence2'], row['sentence1']], label= int(row['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8165b5af-307a-47d1-bddd-02346d6f7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for example in paws_test_examples:\n",
    "    prediction = infer(example.texts[0], example.texts[1])  \n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7db9bf0f-b66a-4436-b907-3ef42d028f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9755\n",
      "Precision: 0.9651810584958217\n",
      "Recall: 0.979920814479638\n"
     ]
    }
   ],
   "source": [
    "true_labels = [example.label for example in paws_test_examples]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4894ab1-7ae4-4b41-9477-55176beb680c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold</th>\n",
       "      <th>genre</th>\n",
       "      <th>pairID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259676</td>\n",
       "      <td>In the past, I have found that there is no poi...</td>\n",
       "      <td>You should prepare a speech.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>244447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88755</td>\n",
       "      <td>There is a persistent myth that the Egyptian m...</td>\n",
       "      <td>The Egyptian military was involved in the assa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>generated</td>\n",
       "      <td>365127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270193</td>\n",
       "      <td>The party of the proletariat is the party of t...</td>\n",
       "      <td>The party of the proletariat is the party of t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>generated</td>\n",
       "      <td>310832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164269</td>\n",
       "      <td>If you're a good swimmer, it's a good idea to ...</td>\n",
       "      <td>The shallow end of the pool is good for swimming.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>36248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6435</td>\n",
       "      <td>I was not in a position to take any action, bu...</td>\n",
       "      <td>The man did not have the power to take any act...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>52946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            premise  \\\n",
       "0  259676  In the past, I have found that there is no poi...   \n",
       "1   88755  There is a persistent myth that the Egyptian m...   \n",
       "2  270193  The party of the proletariat is the party of t...   \n",
       "3  164269  If you're a good swimmer, it's a good idea to ...   \n",
       "4    6435  I was not in a position to take any action, bu...   \n",
       "\n",
       "                                          hypothesis        gold      genre  \\\n",
       "0                       You should prepare a speech.  entailment  generated   \n",
       "1  The Egyptian military was involved in the assa...     neutral  generated   \n",
       "2  The party of the proletariat is the party of t...     neutral  generated   \n",
       "3  The shallow end of the pool is good for swimming.  entailment  generated   \n",
       "4  The man did not have the power to take any act...  entailment  generated   \n",
       "\n",
       "   pairID  \n",
       "0  244447  \n",
       "1  365127  \n",
       "2  310832  \n",
       "3   36248  \n",
       "4   52946  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "498be4a8-5267-4ff0-9de9-5f0b809765a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = test_data[test_data[\"gold\"]!= \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "606668a4-d868-4c78-86c3-b1c05f25afca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data_labels = []\n",
    "for i in test_data[\"gold\"]:\n",
    "    if i == \"entailment\":\n",
    "        test_data_labels.append(1)\n",
    "    else:\n",
    "        test_data_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e6e9000-3621-4116-9d35-a4eecb817e11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold</th>\n",
       "      <th>genre</th>\n",
       "      <th>pairID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259676</td>\n",
       "      <td>In the past, I have found that there is no poi...</td>\n",
       "      <td>You should prepare a speech.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>244447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164269</td>\n",
       "      <td>If you're a good swimmer, it's a good idea to ...</td>\n",
       "      <td>The shallow end of the pool is good for swimming.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>36248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6435</td>\n",
       "      <td>I was not in a position to take any action, bu...</td>\n",
       "      <td>The man did not have the power to take any act...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>52946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15293</td>\n",
       "      <td>\"I'll be sure to leave the lights on for you,\"...</td>\n",
       "      <td>She'll be sure to leave the lights off for you.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>generated_revised</td>\n",
       "      <td>339475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264807</td>\n",
       "      <td>This small town has been known for its dairy p...</td>\n",
       "      <td>This town is known for its dairy products, and...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>generated</td>\n",
       "      <td>272068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            premise  \\\n",
       "0  259676  In the past, I have found that there is no poi...   \n",
       "3  164269  If you're a good swimmer, it's a good idea to ...   \n",
       "4    6435  I was not in a position to take any action, bu...   \n",
       "6   15293  \"I'll be sure to leave the lights on for you,\"...   \n",
       "7  264807  This small town has been known for its dairy p...   \n",
       "\n",
       "                                          hypothesis           gold  \\\n",
       "0                       You should prepare a speech.     entailment   \n",
       "3  The shallow end of the pool is good for swimming.     entailment   \n",
       "4  The man did not have the power to take any act...     entailment   \n",
       "6    She'll be sure to leave the lights off for you.  contradiction   \n",
       "7  This town is known for its dairy products, and...     entailment   \n",
       "\n",
       "               genre  pairID  label  \n",
       "0          generated  244447      1  \n",
       "3          generated   36248      1  \n",
       "4          generated   52946      1  \n",
       "6  generated_revised  339475      0  \n",
       "7          generated  272068      1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"label\"] = test_data_labels\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38a31719-cab7-467a-b7c1-7cee9c44cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = []\n",
    "for i, row in test_data.iterrows():\n",
    "    test_examples.append(InputExample(texts=[row['premise'], row['hypothesis']], label= int(row['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "222921b1-f89a-449b-b13e-d0de2595cd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for example in test_examples:\n",
    "    prediction = infer(example.texts[0], example.texts[1])  \n",
    "    test_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ac6ced8-f334-40ca-8805-d481009a359c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9376558603491272\n",
      "Recall: 0.6071044133476857\n",
      "F1-Score: 0.7370140476968311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "true_labels = [example.label for example in test_examples]\n",
    "\n",
    "precision = precision_score(true_labels, test_predictions)\n",
    "recall = recall_score(true_labels, test_predictions)\n",
    "f1 = f1_score(true_labels, test_predictions)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13234c00-a209-4e52-ab95-f7bf4c719894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-6:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
